# Comparison of image generating models based on VQGAN and LDM

This repository contains the scripts I used for my bachelor's thesis along with a description on how to reproduce the results.

### Sample from VQGAN
To sample 50 images of each class of the ImageNet dataset from the VQGAN, one needs to clone the original repository: https://github.com/CompVis/taming-transformers and place the `sample_VQGAN.py` script in the same folder and execute it.
Samples are then found under `/logs/2021-04-03T19-39-50_cin_transformer/samples/top_k_600_temp_1.00_top_p_0.92/1095554`.

### Sample from LDM
To sample 50 images of each class of the ImageNet dataset from the LDM, one needs to execute the `sample_LDM.py` script.
Samples are then found under `/samples`.

### Calculate IS and FID
To calculate the Inception Score (IS) and the Fr√©chet Inception Distance (FID), one needs to download the stats for the ImageNet validation set from http://bioinf.jku.at/research/ttur/ttur_stats/fid_stats_\gls{in}_valid.npz and then
execute the `calculate_IS_FID.py` script.

### Classify images with Inception-V3 model
To classify the generated images with an Inception-V3 model, one needs to execute the `classification_V3.py` script.
To see whether the accuracy changes when superclasses from https://github.com/s-kumano/imagenet-superclass are used, one needs to execute the `superclass.py` script.

Both classification scripts save an `accuracies.csv`, a `probs.csv` and a `count.csv` file for the corresponding images.
The `count.csv` file contains the number of times a specific class was the predicted class for an image.

### Results
My results for classifying with the Inception-V3 model can be found in the results folder.

### Plot results
The results for the classification with the Inception-V3 model can be plotted with the `plot.py` script.
To compare the accuracy of the the normal classification with the superclass classification, one needs to execute the `plot_accuracies_sc.py` script.

